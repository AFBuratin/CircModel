---
title: "Benchmark De methods"
author: "Enrico Gaffo"
date: "28/10/2021"
output: 
  html_document: 
    toc: yes
    toc_float: yes
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(SummarizedBenchmark)
library("magrittr")
# library(plotROC)
library(data.table)
library(qs)
library(DT)

library("limma")
library("edgeR")
library("DESeq2")
library("tximport")
library(glmGamPoi)
library(zinbwave)
library(scran)

library(BiocParallel)
library(batchtools)

# install.packages("devtools", Ncpus = multicoreWorkers())
# library(devtools)
# install_github("lichen-lab/circMeta", Ncpus = multicoreWorkers())
library(circMeta)
```

```{r}
nWorkers <- multicoreWorkers() # 24

## load simulated data
simulated_datasets_qs <- "/sharedfs01/circrna/CircModel/semi_parametric_sim/trimmed_simulated_datasets.qs"

sim_ds_list <- qread(file = simulated_datasets_qs, nthreads = nWorkers)
```

```{r}
## separate DE and not-DE simulations
de_ds_list <- sim_ds_list[!grepl("mock", names(sim_ds_list))]
names(de_ds_list) <- paste0(names(de_ds_list), "_de")
not_de_ds_list <- sim_ds_list[grepl("mock", names(sim_ds_list))]
```

# Bench design

```{r}
# simData <- de_ds_list$N03_bulk$Datasets$sim.data.list[[1]]
# 
# mycounts <- round(simData$counts)
# mycoldat <- data.frame(condition = factor(simData$colData[colnames(mycounts), "Group"]))
# # rownames(mycoldat) <- colnames(mycounts)
# mydat <- list(coldat = mycoldat, 
#               cntdat = mycounts,
#               status = as.integer(simData$rowData[rownames(mycounts), "DE.ind"]))
# 
# bd <- BenchDesign(data = mydat)

bd <- BenchDesign()
```

## Methods

### DESeq2 family

```{r}
## DESeq2 family

## 1. DESeq2 defaults
deseq2_run <- function(countData, colData, design, contrast) {

  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  dds <- DESeq2::DESeq(dds)
  res <- DESeq2::results(dds, 
                 contrast = contrast, 
                 test = "Wald", 
                 independentFiltering = F)
  # or to shrink log fold changes association with condition:
  # lfcShrink(dds, coef="condition_trt_vs_untrt", type="apeglm")
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)

}

## 2. use LRT 
deseq2lrt_run <- function(countData, colData, design, contrast) {
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  dds <- DESeq2::DESeq(dds, 
               test = "LRT",
               reduced = ~ 1)
  
  res <- DESeq2::results(dds, independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 3. use betaPrior
deseq2bp_run <- function(countData, colData, design, contrast) {
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  dds <- DESeq2::DESeq(dds, 
               betaPrior = T)
  res <- DESeq2::results(dds, 
                         contrast = contrast, 
                         test = "Wald", 
                         independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 4. use recommended parameters for single-cell data
## https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#recommendations-for-single-cell-analysis
## Use test="LRT"
## useT=TRUE
## minmu=1e-6 The default setting of minmu was benchmarked on bulk RNA-seq and 
##            is not appropriate for single cell data when the expected count is 
##            often much less than 1
## minReplicatesForReplace=Inf. 
## setting sizeFactors from scran::computeSumFactors. The default size factors 
##         are not optimal for single cell count matrices
## set fitType = "glmGamPoi"
deseq2zi_run <- function(countData, colData, design, contrast) {
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  
  dds <- DESeq2::DESeq(dds, 
                       # quiet = TRUE, 
                       sfType = "poscounts", 
                       useT = TRUE, 
                       minmu = 1e-6, 
                       minReplicatesForReplace = Inf, 
                       test = "LRT", 
                       reduced = ~ 1)
  # DESeq2::results(dds, contrast = contrast)
  res <- DESeq2::results(dds, independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 5. use recommended parameters for single-cell data and the genefilter::shorth
## in estimating  the size factors (parameter 'locfunc')
## ?estimateSizeFactors
## locfunc: a function to compute a location for a sample. By default, the 
##          median is used. However, especially for low counts, the shorth 
##          function from the genefilter package may give better results.
deseq2lc_run <- function(countData, colData, design, contrast) {
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  
  dds <- DESeq2::estimateSizeFactors(dds, type = "poscounts", 
                                     locfunc = function(x){ 
                                       tryCatch(
                                         {
                                           genefilter::shorth(x)
                                         },
                                         error = function(cond) {
                                           warning(paste("The 'shorth' function failed with the following message:\n", 
                                                         cond, 
                                                         "Will try to use 'half.range.mode' instead"))
                                           genefilter::half.range.mode(x)}
                                       ) })
  
  dds <- DESeq2::DESeq(dds, 
                       # quiet = TRUE, 
                       # sfType = "poscounts", 
                       useT = TRUE, 
                       minmu = 1e-6, 
                       minReplicatesForReplace = Inf, 
                       test = "LRT", 
                       reduced = ~ 1)
  # results(dds, contrast = contrast)
  res <- DESeq2::results(dds, independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 6. use recommended parameters for single-cell data and the scran::computeSumFactors
## to estimate the size factors
## 'setting sizeFactors from scran::computeSumFactors. The default size factors 
##  are not optimal for single cell count matrices'
deseq2sc_run <- function(countData, colData, design, contrast) {
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  
  # "sizeFactors"(dds) <- 
  #   DESeq2::sizeFactors(scran::computeSumFactors(dds, 
  #                                                clusters = SummarizedExperiment::colData(dds)$condition))
  dds <- scran::computeSumFactors(dds, 
                                  clusters = SummarizedExperiment::colData(dds)$condition)
  
  dds <- DESeq2::DESeq(dds, 
                       # quiet = TRUE, 
                       useT = TRUE, 
                       minmu = 1e-6, 
                       minReplicatesForReplace = Inf, 
                       test = "LRT", 
                       reduced = ~ 1)
  # DESeq2::results(dds, contrast = contrast)
  res <- DESeq2::results(dds, independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 7. By using the argument fitType="glmGamPoi", one can leverage the faster NB GLM 
## engine written by Constantin Ahlmann-Eltze. Note that glmGamPoiâ€™s interface in 
## DESeq2 requires use of test="LRT" and specification of a reduced design.
## https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#speed-up-and-parallelization-thoughts
deseq2gpLrt_run <- function(countData, colData, design, contrast) {
  
  library(glmGamPoi)
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  
  dds <- DESeq2::DESeq(dds, 
                       # quiet = TRUE, 
                       sfType = "poscounts", 
                       # useT = TRUE, 
                       minmu = 1e-6, 
                       minReplicatesForReplace = Inf, 
                       fitType = "glmGamPoi",
                       test = "LRT", 
                       reduced = ~ 1)
  # DESeq2::results(dds, contrast = contrast)
  res <- DESeq2::results(dds, independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 8. use ZinbWave weights
deseq2zw_run <- function(countData, colData, design, contrast, weights) {
  
  tictoc::tic()
  
  dds <- DESeq2::DESeqDataSetFromMatrix(countData, colData = colData, design = design)
  
  # if(is.null(weights)){
  #   message("Weights expected but NULL was given. DESeq2 will not use weights")
  # }else{
  #   weights[which(weights < 1e-6)] <- 1e-06
  #   assays(dds, withDimnames =F, "weights")[["weights"]] <- weights
  # }
  
  dds <- DESeq2::DESeq(dds, 
                       # quiet = TRUE, 
                       sfType = "poscounts", 
                       # useT = TRUE, 
                       minmu = 1e-6, 
                       minReplicatesForReplace = Inf, 
                       test = "LRT", 
                       reduced = ~ 1)
  # DESeq2::results(dds, contrast = contrast)
  res <- DESeq2::results(dds, independentFiltering = F)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## post functions
deseq2_pv <- function(x) { 
  res <- x$res$pvalue 
  res[is.na(res)] <- 1
  res
}

deseq2_apv <- function(x) { 
  res <- x$res$padj
  res[is.na(res)] <- 1
  res
}

deseq2_lfc <- function(x) { x$res$log2FoldChange }

deseq2_time <- function(x) { rep(as.numeric(x$runtime), nrow(x$res)) }
```

### edgeR family

```{r}
## edgeR family

## 1. default edgeR
edgeR_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y) # method = "TMMwsp" for zero counts?
  # des <- model.matrix(design)
  des <- model.matrix(~group, data = y$samples)
  y <- edgeR::estimateDisp(y, des) # min.row.sum = 5 default. Change?
  fit <- edgeR::glmFit(y, des)
  res <- edgeR::glmLRT(fit, coef=2)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 2. robust
edgeRrbst_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y)
  # des <- model.matrix(design)
  des <- model.matrix(~group, data = y$samples)
  y <- edgeR::estimateGLMRobustDisp(y, des) #maxit = 6
  fit <- edgeR::glmQLFit(y = y, dispersion = y$tagwise.dispersion, 
                 robust = TRUE, design = des)
  res <- edgeR::glmLRT(fit, coef = 2)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 3. 50 degrees of freedom
edgeRrbst50df_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y)
  # des <- model.matrix(design)
  des <- model.matrix(~group, data = y$samples)
  y <- edgeR::estimateGLMRobustDisp(y = y, des, prior.df = 50) #maxit = 6
  fit <- edgeR::glmQLFit(y = y, dispersion = y$tagwise.dispersion, 
                 robust = TRUE, design = des)
  res <- edgeR::glmLRT(fit, coef = 2)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 4. auto estimation of df
edgeRrbstEdf_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y)
  # des <- model.matrix(design)
  des <- model.matrix(~group, data = y$samples)
  y <- edgeR::estimateDisp(y, des) #maxit = 6
  fit <- edgeR::glmQLFit(y = y, dispersion = y$tagwise.dispersion, 
                 robust = TRUE, design = des)
  res <- edgeR::glmLRT(fit, coef = 2)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 5. ZinbWave weights
edgeRzw_run <- function(countData, group, design, weights) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y$weights <- weights
  y <- edgeR::calcNormFactors(y)
  # des <- model.matrix(design)
  des <- model.matrix(~group, data = y$samples)
  y <- edgeR::estimateGLMRobustDisp(y, des) # estimateDisp(y, des)?
  fit <- edgeR::glmFit(y, des) #glmQLFit?
  res <- edgeR::glmLRT(fit, coef = 2)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## 6. Quasi-likelihood dispersion estimate and empirical Bayes quasi-likelihood F-tests
## glmQLFit gives special attention to handling of zero counts
edgeRql_run <- function(countData, group, design, weights) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y)
  # des <- model.matrix(design)
  des <- model.matrix(~group, data = y$samples)
  y <- edgeR::estimateDisp(y = y, design = des, robust = TRUE)
  fit <- edgeR::glmQLFit(y, design = des, robust = TRUE)
  res <- edgeR::glmQLFTest(fit, coef = 2)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## post functions
edgeR_pv <- function(x) { 
  res <- x$res$table$PValue 
  res[is.na(res)] <- 1
  res
}

edgeR_apv <- function(x) {
  res <- p.adjust(p = x$res$table$PValue, method = "BH")
  # res <- topTags(x, number = Inf, sort.by = "none")$table$FDR
  res[is.na(res)] <- 1
  res
}

edgeR_lfc <- function(x) { x$res$table$logFC }

edgeR_time <- function(x) { rep(as.numeric(x$runtime), nrow(x$res)) }
```

### limma-voom family

```{r}
## limma-voom family
voom_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y)
  des <- model.matrix(design)
  y <- limma::voom(y, des)
  res <- limma::eBayes(limma::lmFit(y, des))
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## estimation of df.prior and var.prior be robustified against outlier sample variances
voomRbst_run <- function(countData, group, design) {

  tictoc::tic()
  
  y <- edgeR::DGEList(countData, group = group)
  y <- edgeR::calcNormFactors(y)
  des <- model.matrix(design)
  y <- limma::voom(y, des)
  res <- limma::eBayes(limma::lmFit(y, des), robust = T)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## voom quantile normalization
voomQn_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  des <- model.matrix(design)
  voom.data <- limma::voom(countData, 
                           design = des, 
                           normalize.method = 'quantile')
  res <- limma::eBayes(limma::lmFit(voom.data, design = des))
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## limma-voom code as in the vignette (no prior edgeR; mind the robust = T param)
voomSimple_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  des <- model.matrix(design)
  res <- limma::eBayes(limma::lmFit(limma::voom(counts = countData, 
                                                design = des), 
                                    des), 
                       robust = TRUE)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}


## voomLmFit is more robust to zero counts than calling voom, 
## duplicateCorrelation and lmFit separately and provides more rigorous error rate control.
voomLmFit_run <- function(countData, group, design) {
  
  tictoc::tic()
  
  des <- model.matrix(design)
  ## Empirical sample quality weights will be estimated if sample.weights=TRUE 
  ## or if var.design or var.group are non-NULL. In that case, voomLmFit is 
  ## analogous to running voomWithQualityWeights followed by lmFit.
  ## voomLmFit is usually followed by running eBayes on the fitted model object. 
  res <- limma::eBayes(edgeR::voomLmFit(counts = countData, 
                                        design = des, 
                                        # block = NULL, 
                                        # prior.weights = NULL,
                                        sample.weights = TRUE,
                                        # var.design = NULL, 
                                        # var.group = NULL, 
                                        # lib.size = NULL, 
                                        # normalize.method = "none",
                                        # span = 0.5, 
                                        # plot = FALSE, 
                                        save.plot = FALSE))
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

# limma-voom with ZINBWaVE weights
voomZw_run <- function(countData, group, design, weights) {
  
  tictoc::tic()
  
  des <- model.matrix(design)
  v <- limma::voom(counts = countData, 
                   design = des, 
                   plot = FALSE, 
                   weights = weights)
  # v$weights <- v$weights * weights
  fit <- limma::lmFit(v, design = des, weights = v$weights)
  # fit$df.residual <- rowSums(weights) - ncol(design)
  res <- limma::eBayes(fit, robust = T)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

# voomWithQualityWeights

## post functions
voom_pv <- function(x) { 
  res <- x$res$p.value[, 2] # res <- x$F.p.value	?
  res[is.na(res)] <- 1
  res
}

voom_apv <- function(x) {
  # res <- p.adjust(p = x$p.value[, 2], method = "BH")
  res <- limma::topTable(x$res, number = Inf, sort.by = "none")$adj.P.Val
  res[is.na(res)] <- 1
  res
}

voom_lfc <- function(x) {
  # x$coefficients[, 2]
  limma::topTable(x$res, number = Inf, sort.by = "none")$logFC
}

voom_time <- function(x) { rep(as.numeric(x$runtime), nrow(x$res)) }
```

### circMeta

```{r}
## circMeta
cMeta_run <- function(countData, group, sf = TRUE) {
  
  tictoc::tic()
  
  groupVar <- group 
  names(groupVar) <- colnames(countData)
  countData <- apply(countData, 2, function(x) {storage.mode(x) <- 'integer'; x})
  m = rowMeans(countData)

  sfs = colSums(countData)
  sfs = sfs / min(sfs)
  if(sf) countData = sweep(countData, 2, sfs, FUN='/')
  n0 = sum(groupVar == levels(groupVar)[1]) 
  n1 = sum(groupVar == levels(groupVar)[2]) # assume 2 levels factor groups
  m0 = rowMeans(countData[, groupVar == levels(groupVar)[1]])
  m1 = rowMeans(countData[, groupVar == levels(groupVar)[2]])
  n  = nrow(countData)
  pval = rep(1, n)
  for(i in 1:n){
    z = (m1[i] - m0[i]) / sqrt(m1[i] / n1 + m0[i] / n0)
    pval[i] = 2 * pnorm(-abs(z))
  }
  
  # fdr = p.adjust(pval, method = 'fdr')
  lfc <- log( (m1 + 1) / (m0 + 1), 2)
  
  names(pval) <- rownames(countData)
  res <- data.frame(p.value = pval, 
                    logFC = lfc)
  
  runtime <- tictoc::toc(log = F, quiet = T)
  
  list(res = res, 
       runtime = runtime$toc - runtime$tic)
}

## post functions
cMeta_pv <- function(x) { 
  res <- x$res$p.value
  res[is.na(res)] <- 1
  res
}

cMeta_apv <- function(x) {
  res <- p.adjust(x$res$p.value, method = "BH")
  res[is.na(res)] <- 1
  res
}

cMeta_lfc <- function(x) { x$res$logFC }

cMeta_time <- function(x) { rep(as.numeric(x$runtime), nrow(x$res)) }
```

### Other

```{r}
# poissonSeq <- function(countData, group, design) {
#     library(PoissonSeq)
#     dat = list(n = count.matrix(cdata), 
#                y=sample.annotations(cdata)$condition, 
#                pair = FALSE, 
#                type = 'twoclass', 
#                gname=rownames(count.matrix(cdata)))
#     PS.test = PoissonSeq::PS.Main(dat)
#     PS.nc = PS.test$nc
#     PS.gname = rownames(PS.test)
#     PS.tt = PS.test$tt
#     PS.pvalue = PS.test$pval
#     PS.FDR = PS.test$fdr
#     PS.logfc =  PS.test$log.fc
#     result.table = data.frame('nc' = PS.nc, 
#     'Genename' = PS.gname, 
#     'tt' = PS.tt, 
#     'pvalue' = PS.pvalue, 
#     'FDR'=PS.FDR, 'log.fc' = PS.logfc)
# }

# ROTS <- function(countData, group, design) {
#     library(ROTS)
#     log=F
#     transformation<-T
#     normalize<-T
#     if(normalize&&transformation){
#     if(transformation){
#       log=TRUE
#       nf <- edgeR::calcNormFactors(count.matrix(cdata), method = 'TMM' )
#       voom.data <- limma::voom(count.matrix(cdata),
#                                design = model.matrix(~factor(sample.annotations(cdata)$condition)),
#                                lib.size = colSums(count.matrix(cdata)) * nf)
#       Exp <- voom.data$E
#     }else{
#       edgeR.dgelist <- edgeR::DGEList(counts = count.matrix(cdata),
#                                       group = factor(sample.annotations(cdata)$condition))
#       edgeR.dgelist <- edgeR::calcNormFactors(edgeR.dgelist, method = 'TMM')
#       Factors <- edgeR.dgelist$samples$lib.size * edgeR.dgelist$samples$norm.factors
#       Exp <- t(t(edgeR.dgelist$counts)/Factors) * mean(Factors)
#     }
#   }else{
#     Exp <- count.matrix(cdata)
#   }
# 
# 
#   results <- ROTS::ROTS(data = Exp,
#                         groups = as.numeric(as.character(factor(sample.annotations(cdata)$condition))),
#                         K = NULL, B = 1000, log = log)
#   rots.pvalues <- results$pvalue
#   rots.logFC <- results$logfc
#   rots.FDR <- results$FDR
#   result.table <- data.frame('pvalue' = rots.pvalues, 'logFC' = rots.logFC, 'FDR' = rots.FDR)
# }

# baySeq <- function(countData, group, design) {
#     
#     baySeq.cd <- new('countData',
#                      data = countData,
#                      replicates = group,
#                      groups = list(NDE = rep(1, length(design)),
#                                    DE = design))
#     
#     libsizes(baySeq.cd) <- baySeq::getLibsizes(baySeq.cd, estimationType = "edgeR")
#     
#     baySeq.cd <- baySeq::getPriors.NB(baySeq.cd,
#                                       # samplesize = sample.size,
#                                       equalDispersions = TRUE,
#                                       estimation = "QL",
#                                       cl = NULL)
#     baySeq.cd <- baySeq::getLikelihoods.NB(baySeq.cd,
#                                            # prs = c(0.5, 0.5), 
#                                            pET = "BIC", 
#                                            cl = NULL)
#     baySeq.cd@annotation <- data.frame(rowID = rownames(baySeq.cd@data),
#                                        row.names = rownames(baySeq.cd@data))
#     baySeq.posteriors.DE <- exp(baySeq.cd@posteriors)[, 'DE']
#     baySeq.FDR <- baySeq::topCounts(baySeq.cd, group = 'DE',
#                                     FDR = 1)$FDR.DE[match(rownames(countData),
#                                                           rownames(baySeq::topCounts(baySeq.cd,
#                                                                                      group = 'DE', FDR = 1)))]
#     baySeq.score <- 1 - baySeq.FDR
#     data.frame('FDR' = baySeq.FDR, 'score' = baySeq.score, 'posterior.DE' = baySeq.posteriors.DE)
# }

# SAMseq <- function(countData, group, design) {
#     library(samr)
#   condition.12 <- rep(1, length(sample.annotations(cdata)$condition))
#   condition.12[which(sample.annotations(cdata)$condition == levels(factor(sample.annotations(cdata)$condition))[2])] <- 2
#   SAMseq.test <- samr::SAMseq(count.matrix(cdata), condition.12, resp.type = 'Two class unpaired', geneid = rownames(count.matrix(cdata)), genenames = rownames(count.matrix(cdata)), nperms = 100, nresamp = 20, 
#                               fdr.output = 1)
#   SAMseq.result <- rbind(SAMseq.test$siggenes.table$genes.up, SAMseq.test$siggenes.table$genes.lo)
#   SAMseq.statistic <- rep(0, nrow(count.matrix(cdata)))
#   SAMseq.statistic[match(SAMseq.result[, 1], rownames(count.matrix(cdata)))] <- as.numeric(SAMseq.result[, 3])
#   SAMseq.FDR <- rep(1, nrow(count.matrix(cdata)))
#   SAMseq.FDR[match(SAMseq.result[, 1], rownames(count.matrix(cdata)))] <- as.numeric(SAMseq.result[, 5])/100
#   SAMseq.score <- 1 - SAMseq.FDR
#   result.table <- data.frame('statistic' = SAMseq.statistic, 'FDR' = SAMseq.FDR, 'score' = SAMseq.score)
# }


# DeSingle_run <- function(countData, group, design) {
#   #Load library and the test data for DEsingle
#   library(DEsingle)
#   library(SingleCellExperiment)
#   data(TestData)
#   
#   # Convert the test data in DEsingle to SingleCellExperiment data representation
#   sce <- SingleCellExperiment(assays = list(counts = countData))
#   
#   # Detecting the DE genes with SingleCellExperiment input sce
#   results <- DEsingle(counts = sce, group = group)
#   
#   # Dividing the DE genes into 3 categories at threshold of FDR < 0.05
#   results.classified <- DEtype(results = results, threshold = 0.05)
#   
#   # Dividing the DE genes into 3 categories at threshold of FDR < 0.05
#   # results.classified <- DEtype(results = results, threshold = 1)
#   
#   # results$emdall
#   pValMat <- as.matrix(results$pvalue)
#   colnames(pValMat) <- c("adjP")
#   statInfo <- cbind("foldChange" = results$foldChange)
#   list("pValMat" = pValMat, "statInfo" = statInfo)
# }# END - function: DeSingle

# #TODO
# _apv <- function(x) {}
# 
# _lfc <- function(x) {}
# 
# _time <- function(x) {}
```


## Add memthods to the bench

```{r}
## add memthods to the bench
bd <- bd %>%
  addMethod(label = "DESeq2_Dt_WaT", ## DESeq2, default parameters, Wald test
            func = deseq2_run, 
            # post = deseq2_pv,
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2", pkg_vers = as.character(packageVersion("DESeq2"))),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "DESeq2_Dt_LRT", ## DESeq2, default parameters, likelihood ratio test
            func = deseq2lrt_run, 
            # post = deseq2_pv,
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2", pkg_vers = as.character(packageVersion("DESeq2"))),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "DESeq2_Lc_LRT", ## DESeq2, parameters for low counts, likelihood ratio test
            func = deseq2lc_run, 
            # post = deseq2_pv,
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2", pkg_vers = as.character(packageVersion("DESeq2"))),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "DESeq2_Zi_LRT", ## DESeq2, parameters for single-cell data, likelihood ratio test
            func = deseq2zi_run, 
            # post = deseq2_pv, 
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2", pkg_vers = as.character(packageVersion("DESeq2"))),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "DESeq2_Sc_LRT", ## DESeq2, parameters for single-cell data and scran::computeSumFactors, likelihood ratio test
            func = deseq2sc_run, 
            # post = deseq2_pv,
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2/scran",
                        pkg_vers = paste(as.character(packageVersion("DESeq2")),
                                         as.character(packageVersion("scran")),
                                         sep = "/")),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat,
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "DESeq2_GP_LRT", ## DESeq2, Gamma-Poisson, likelihood ratio test
            func = deseq2gpLrt_run, 
            # post = deseq2_pv, 
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2/glmGamPoi", 
                        pkg_vers = paste(as.character(packageVersion("DESeq2")), 
                                         as.character(packageVersion("glmGamPoi")), 
                                         sep = "/")),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "DESeq2_ZW_LRT", ## DESeq2, ZinbWave, likelihood ratio test
            func = deseq2zw_run, 
            # post = deseq2_pv, 
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2/zinbwave", 
                        pkg_vers = paste(as.character(packageVersion("DESeq2")), 
                                         as.character(packageVersion("zinbwave")), 
                                         sep = "/")),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"),
                                 weights = weights)) %>%
  addMethod(label = "DESeq2_BP_WaT", ## DESeq2, betaPrior=T, Wald test
            func = deseq2bp_run, 
            # post = deseq2_pv,
            post = list(pv = deseq2_pv,
                        adj_pv = deseq2_apv,
                        lfc = deseq2_lfc,
                        runtime = deseq2_time),
            meta = list(pkg_name = "DESeq2", pkg_vers = as.character(packageVersion("DESeq2"))),
            params = rlang::quos(countData = cntdat,
                                 colData = coldat, 
                                 design = ~condition,
                                 contrast = c("condition", "2", "1"))) %>%
  addMethod(label = "edgeR_Dt_LRT", ## edgeR, defaults, likelihood ratio test 
            func = edgeR_run, 
            # post = edgeR_pv,
            post = list(pv = edgeR_pv,
                        adj_pv = edgeR_apv,
                        lfc = edgeR_lfc,
                        runtime = edgeR_time),
            meta = list(pkg_name = "edgeR", pkg_vers = as.character(packageVersion("edgeR"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
  addMethod(label = "edgeR_ZW_LRT", ## edgeR, ZinbWave, likelihood ratio test 
            func = edgeRzw_run, 
            # post = edgeR_pv,
            post = list(pv = edgeR_pv,
                        adj_pv = edgeR_apv,
                        lfc = edgeR_lfc,
                        runtime = edgeR_time),
            meta = list(pkg_name = "edgeR/zinbwave", 
                        pkg_vers = paste(as.character(packageVersion("edgeR")), 
                                         as.character(packageVersion("zinbwave")), 
                                         sep = "/")),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition,
                                 weights = weights)) %>%
  addMethod(label = "edgeR_rbst_LRT", ## edgeR, robust dispersion estimate, likelihood ratio test 
            func = edgeRrbst_run, 
            # post = edgeR_pv,
            post = list(pv = edgeR_pv,
                        adj_pv = edgeR_apv,
                        lfc = edgeR_lfc,
                        runtime = edgeR_time),
            meta = list(pkg_name = "edgeR", pkg_vers = as.character(packageVersion("edgeR"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
  addMethod(label = "edgeR_rbst50df_LRT", ## edgeR, robust dispersion estimate with 50 degrees of freedom, likelihood ratio test 
            func = edgeRrbst50df_run, 
            # post = edgeR_pv,
            post = list(pv = edgeR_pv,
                        adj_pv = edgeR_apv,
                        lfc = edgeR_lfc,
                        runtime = edgeR_time),
            meta = list(pkg_name = "edgeR", pkg_vers = as.character(packageVersion("edgeR"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
  addMethod(label = "edgeR_rbstEdf_LRT", ## edgeR, robust dispersion estimate with autodetermied number of degrees of freedom, likelihood ratio test 
            func = edgeRrbstEdf_run, 
            # post = edgeR_pv,
            post = list(pv = edgeR_pv,
                        adj_pv = edgeR_apv,
                        lfc = edgeR_lfc,
                        runtime = edgeR_time),
            meta = list(pkg_name = "edgeR", pkg_vers = as.character(packageVersion("edgeR"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
    addMethod(label = "edgeR_rbst_QFT", ## edgeR, robust dispersion estimate, empirical Bayes quasi-likelihood F-test 
            func = edgeRql_run, 
            # post = edgeR_pv,
            post = list(pv = edgeR_pv,
                        adj_pv = edgeR_apv,
                        lfc = edgeR_lfc,
                        runtime = edgeR_time),
            meta = list(pkg_name = "edgeR", pkg_vers = as.character(packageVersion("edgeR"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
  addMethod(label = "voom_Dt_MFT", ## limma-voom, defauls, moderated F-statistic (or is it t-stats ?) 
            func = voom_run, 
            # post = voom_pv,
            post = list(pv = voom_pv,
                        adj_pv = voom_apv,
                        lfc = voom_lfc,
                        runtime = voom_time),
            meta = list(pkg_name = "limma-voom", pkg_vers = as.character(packageVersion("limma"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
    addMethod(label = "voom_Rb_MFT", ## limma-voom, use robust est, moderated F-statistic (or is it t-stats ?) 
            func = voomRbst_run, 
            # post = voom_pv,
            post = list(pv = voom_pv,
                        adj_pv = voom_apv,
                        lfc = voom_lfc,
                        runtime = voom_time),
            meta = list(pkg_name = "limma-voom", pkg_vers = as.character(packageVersion("limma"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
    addMethod(label = "voom_Qn_MFT", ## limma-voom, use quantile normalization, moderated F-statistic (or is it t-stats ?) 
            func = voomQn_run, 
            # post = voom_pv,
            post = list(pv = voom_pv,
                        adj_pv = voom_apv,
                        lfc = voom_lfc,
                        runtime = voom_time),
            meta = list(pkg_name = "limma-voom", pkg_vers = as.character(packageVersion("limma"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
    addMethod(label = "voom_Sp_MFT", ## limma-voom, defaults as in vignette, moderated F-statistic (or is it t-stats ?) 
            func = voomSimple_run, 
            # post = voom_pv,
            post = list(pv = voom_pv,
                        adj_pv = voom_apv,
                        lfc = voom_lfc,
                        runtime = voom_time),
            meta = list(pkg_name = "limma-voom", pkg_vers = as.character(packageVersion("limma"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
    addMethod(label = "voom_LF_MFT", ## limma-voom, use voomLmFit, moderated F-statistic (or is it t-stats ?) 
            func = voomLmFit_run, 
            # post = voom_pv,
            post = list(pv = voom_pv,
                        adj_pv = voom_apv,
                        lfc = voom_lfc,
                        runtime = voom_time),
            meta = list(pkg_name = "limma-voom", pkg_vers = as.character(packageVersion("limma"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition)) %>%
  addMethod(label = "voom_ZW_MFT", ## limma-voom, use ZinbWave weigths, moderated F-statistic (or is it t-stats ?) 
            func = voomZw_run, 
            # post = voom_pv,
            post = list(pv = voom_pv,
                        adj_pv = voom_apv,
                        lfc = voom_lfc,
                        runtime = voom_time),
            meta = list(pkg_name = "limma-voom/zinbwave", 
                        pkg_vers = paste(as.character(packageVersion("limma")), 
                                         as.character(packageVersion("zinbwave")), 
                                         sep = "/")),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition,
                                 design = ~coldat$condition,
                                 weights = weights)) %>%
  addMethod(label = "circMeta_Dt_PZT", ## circMeta, defaults, Poisson z-test
            func = cMeta_run, 
            # post = cMeta_pv, 
            post = list(pv = cMeta_pv,
                        adj_pv = cMeta_apv,
                        lfc = cMeta_lfc,
                        runtime = cMeta_time),
            meta = list(pkg_name = "circMeta", pkg_vers = as.character(packageVersion("circMeta"))),
            params = rlang::quos(countData = cntdat,
                                 group = coldat$condition))

bd
```

```{r}
printMethods(bd)
```

### Weight functions

```{r}
compute_weights <- function(countdata, coldat, ...) {
  
  computeExactWeights <- function (model, x) {
    library(zinbwave)
    
    mu <- getMu(model)
    pi <- getPi(model)
    theta <- getTheta(model)
    theta <- matrix(rep(theta, each = ncol(x)), ncol = nrow(x))
    nb_part <- dnbinom(t(x), size = theta, mu = mu)
    zinb_part <- pi * ( t(x) == 0 ) + (1 - pi) *  nb_part
    zinbwg <- ( (1 - pi) * nb_part ) / zinb_part
    zinbwg <- t(zinbwg)
    zinbwg[x > 0] <- 1
    zinbwg[zinbwg < 1e-15] <- 1e-15
    zinbwg
  }
  
  library(zinbwave)
  
  zinbmodel <- zinbFit(Y = countdata,
                       X = model.matrix(~ coldat), 
                       K = 0,
                       # epsilon = nrow(countdata), #1e10
                       commondispersion = TRUE, 
                       verbose = FALSE, 
                       ...) #BPPARAM = BiocParallel::SerialParam()
  
  computeExactWeights(model = zinbmodel,
                      x = countdata)
}
```

```{r}
## set names to (sub)datasets and remove first level of list
datasetList <- 
  unlist(lapply(names(de_ds_list), 
                function(x, y) {
                  simData <- y[[x]]$Datasets$sim.data.list
                  names(simData) <- paste(x, sprintf("%02d", 1:length(simData)), sep = "_")
                  simData
                }, 
                y = de_ds_list), 
         recursive = F)

# subsetIdx <- c(1:3, 31:33, 61:63, # { bulk 3, 5, 10 } x 3
#                91:93, 121:123, 151:153) # { sice 3, 5, 10 } x 3
# subsetIdx <- c(1:2, 31:32, 61:62, 91:92, 121:122, 151:152)
subsetIdx <- 1:length(datasetList) # all
datasetList <- datasetList[subsetIdx]
```

```{r}
## set scheduler for cluster computing
zwcpus <- 8
bpparam <- BatchtoolsParam(workers = length(datasetList), 
                           saveregistry = F,
                           cluster = "slurm",
                           resources = list(ncpus = zwcpus, 
                                            walltime = 3600, # 1h max
                                            memory = 4096) # 4Gb, 2048 2 GByte, 8192 8 Gb
)

## Multithread, single machine
# bpparam <- MulticoreParam(nWorkers)
```

## Prepare dataset and input parameters

```{r prepare_datasets}
## prepare dataset and input parameters
datasetList <- 
  bplapply(datasetList, 
           function(x, compute_weights, zwcpus) {
             
             ## remove rows with at least 3 samples expressed
             mat <- x$counts[rowSums(x$counts > 0) >= 3, ]
             coldata <- x$colData[colnames(mat), ]
             rowdata <- x$rowData[rownames(mat), ]
             discarded.rowData <- x$rowData[!rownames(x$rowData) %in% rownames(mat), ]
             
             ## keep track of runtime spent computing weights with ZinbWave; 
             ## it will be sum up to the running time of methods using weights
             tictoc::tic(msg = "Weights")
             weights <- compute_weights(countdata = mat,
                                        coldat = factor(coldata[, "Group"]),
                                        BPPARAM = BiocParallel::MulticoreParam(workers = zwcpus))
             # weights = NULL, ## only for quick testing. Uncomment above for real weights
             time_weights <- tictoc::toc(log = F, quiet = T)
             
             list(coldat = data.frame(condition = factor(coldata[, "Group"])), 
                  cntdat = mat, 
                  status = as.integer(rowdata[, "DE.ind"]),
                  weights = weights,
                  time_weights = setNames(rep(time_weights$toc - time_weights$tic, nrow(mat)), NULL),
                  discarded.rowData = discarded.rowData,
                  nGenes = nrow(mat))
             
           }, 
           compute_weights = compute_weights,
           zwcpus = zwcpus,
           BPPARAM = bpparam)
```

```{r save_datasets}
## save the processed data sets
datasetList_qs <- "datasetList.qs"
qsave(x = datasetList, 
      file = datasetList_qs, 
      nthreads = multicoreWorkers(), 
      preset = "fast")
```

## Build bench list

```{r build_benches}
## override BPPARAM
parallel_methods <- 4
bpparam$resources$ncpus <- parallel_methods

sbL <- 
  bplapply(datasetList, 
           function(x, bd, parallel_methods) { 
             SummarizedBenchmark::buildBench(bd, data = x, 
                                             # truthCols = "status",
                                             truthCols = c(pv = "status",
                                                           adj_pv = "status", 
                                                           lfc = "status", # LFC(DEC) >= 0.5
                                                           runtime = "time_weights"), 
                                             parallel = T, 
                                             BPPARAM = BiocParallel::MulticoreParam(parallel_methods)) 
           }, 
           bd = bd,
           parallel_methods = parallel_methods,
           BPPARAM = bpparam)
# sbL
```

```{r}
## error handling
# simplify2array(metadata(sbL$N03_bulk_de_02)$sessions[[1]]$results)
# metadata(sbL$N03_bulk_de_02)$sessions[[1]]$results$DESeq2_Sc_LRT
# metadata(sbL$N03_bulk_de_02)$sessions[[1]]$results$DESeq2_Lc_LRT

show_dt <- 
  dcast(melt(rbindlist(lapply(sbL, 
                              function(x)data.table(as.data.frame(simplify2array(metadata(x)$sessions[[1]]$results)), 
                                                    keep.rownames = "Assay")), 
                       idcol = "DS"), 
             id.vars = c("DS", "Assay"), 
             variable.name = "Method"), 
        formula = DS + Method ~ Assay)

show_dt$DS <- factor(show_dt$DS)
show_dt$Method <- factor(show_dt$Method)

datatable(show_dt[adj_pv != "success" | 
                    lfc != "success" | 
                    pv != "success" | 
                    runtime != "success"], 
          caption = "Methods that failed",
          filter = "top", rownames = F)
```


# Performance

```{r}
# availableMetrics()
```

## Add performance 

```{r}
#' Adds performance metrics to a SummarizedBenchmark object
#' param x the SummarizedBenchmark object
#' returns a SummarizedBenchmark with the peformance metrics setted
add_performance_metrics <- 
  function(x) {
    
    ## Notes:
    ## precision (PPV) = 1 - FDR
    ## recall = TPR
    ## specificity = TNR  
    ## FPR = 1 - TNR
    ## FNR = 1 - TPR
    ## F1 = 2 * ( (PPV * TPR) / (PPV + TPR) )
    
    ## add the metrics on the P-values
    x <- SummarizedBenchmark::addPerformanceMetric(x, 
                                                   evalMetric = c("rejections", "TPR", "TNR", "FDR"), #, "FNR"
                                                   assay = "pv")
    
    ## add the metrics on the adjusted P-values
    x <- SummarizedBenchmark::addPerformanceMetric(x, 
                                                   evalMetric = c("rejections", "TPR", "TNR", "FDR"), #, "FNR"
                                                   assay = "adj_pv")
    
    ## add the metrics on the fold changes: TPR
    x <- SummarizedBenchmark::addPerformanceMetric(object = x,
                                                   assay = "lfc",
                                                   evalMetric = "LFC_TPR",
                                                   evalFunction = function(query, truth, lfc_thr = 0.5) {
                                                     ## TPR = TP / (TP + FN)
                                                     is_lfc_larger  <- query >= lfc_thr
                                                     is_lfc_larger[is.na(is_lfc_larger)] <- F
                                                     TP <- sum(is_lfc_larger & truth == 1)
                                                     TP / sum(truth == 1)
                                                   })
    
    ## add the metrics on the fold changes: TNR
    x <- SummarizedBenchmark::addPerformanceMetric(object = x,
                                                   assay = "lfc",
                                                   evalMetric = "LFC_TNR", 
                                                   evalFunction = function(query, truth, lfc_thr = 0.5) {
                                                     ## TNR = TN / N, with N = TN + FP
                                                     is_lfc_lower  <- query < lfc_thr
                                                     is_lfc_lower[is.na(is_lfc_lower)] <- T
                                                     TN <- sum(is_lfc_lower & truth == 0)
                                                     TN / sum(truth == 0)
                                                   })
    
    ## add the metrics on the fold changes: FDR
    x <- SummarizedBenchmark::addPerformanceMetric(object = x,
                                                   assay = "lfc",
                                                   evalMetric = "LFC_FDR", 
                                                   evalFunction = function(query, truth, lfc_thr = 0.5) {
                                                     ## FDR = FP / (FP + TP)
                                                     is_lfc_larger  <- query >= lfc_thr
                                                     is_lfc_larger[is.na(is_lfc_larger)] <- F
                                                     FP <- sum(is_lfc_larger & truth == 0)
                                                     TP <- sum(is_lfc_larger & truth == 1)
                                                     FP / (FP + TP)
                                                   })
    
    ## add the Runtime metric
    x <- SummarizedBenchmark::addPerformanceMetric(object = x,
                                                   assay = "runtime",
                                                   evalMetric = "Runtime",
                                                   evalFunction = function(query, truth, add_weight_time = FALSE) {
                                                     ifelse(add_weight_time, query[1] + truth[1], query[1])
                                                   })
    
    ## return the updated SummarizedBenchmark object
    x
  }
```

```{r add_performance_metrics}
## add the performance metrics to the list of bechDesign
bpparam$resources$ncpus <- 1

sbL <- 
  bplapply(sbL, 
           add_performance_metrics,
           BPPARAM = bpparam)
# BPPARAM = BiocParallel::MulticoreParam(nWorkers))
```

## Estimate performance

```{r estimate_performance}
alpha_targets <- c(0.01, 0.05, 0.1) 
add_weights <- c(FALSE, TRUE)

sbL <- bplapply(sbL, function(x, alphas, add_weights) {
  SummarizedBenchmark::estimatePerformanceMetrics(x, 
                                                  rerun = T,
                                                  alpha = alphas, 
                                                  add_weight_time = add_weights,
                                                  addColData = T)},
  alphas = alpha_targets,
  add_weights = add_weights,
  # BPPARAM = BiocParallel::MulticoreParam(nWorkers))
  BPPARAM = bpparam)

# View(rbindlist(lapply(sbL,
#                       function(x)data.table(as.data.frame(colData(x)),
#                                             keep.rownames = "Met")),
#                idcol = "DS"))
```

```{r save_performance_results}
## save the summarizedBenchmark estimated performance
sumBench_perf_metrics_qs <- "sumBench_perf_metrics.qs"
qsave(x = sbL, 
      file = sumBench_perf_metrics_qs, 
      nthreads = multicoreWorkers(), 
      preset = "fast")
```

# Session info

```{r}
sessionInfo()
```

